
## üöÄ Tecnologias Utilizadas

- üíª **Databricks (runtime baseado em Apache Spark)**
- üêç **PySpark (API de DataFrames)**
- üêò **Delta Lake (armazenamento transacional)**
- üß™ Notebooks interativos com comandos `display()`, `printSchema()` e `count()`

## üìå Principais Conceitos Abordados

### ‚úÖ Lazy Evaluation
Demonstra√ß√£o pr√°tica de como transforma√ß√µes em Spark (ex: `.filter()`, `.select()`) n√£o s√£o executadas at√© uma *a√ß√£o* ser chamada (ex: `.show()`, `.count()`, `.write()`).

### üîÅ Deduplica√ß√£o de Dados
- Identifica√ß√£o de duplicatas com `.groupBy().count()`
- Uso da fun√ß√£o `dropDuplicates()` para eliminar entradas repetidas
- Aplica√ß√£o de `Window Functions` com `row_number()` para manter o registro mais recente por chave de neg√≥cio

### üìä An√°lise Explorat√≥ria
- Contagem total e por categoria (`lead_status`)
- Contagem de valores √∫nicos por coluna com `approx_count_distinct`

## üß™ Simula√ß√£o com Dummy Data

Todos os dados utilizados neste projeto foram **anonimizados** ou gerados sinteticamente para fins educacionais.

### Exemplo de Schema Simulado

| Coluna               | Tipo       | Descri√ß√£o                        |
|----------------------|------------|----------------------------------|
| lead_opportunity_id  | string     | Identificador da oportunidade    |
| lead_status          | string     | Status do lead (ex: CONTACTED)   |
| lead_open_dt         | timestamp  | Data de abertura                 |
| etl_timestamp        | timestamp  | Timestamp de ingest√£o            |
| etl_med_timestamp    | timestamp  | Timestamp intermedi√°rio          |

## üìÇ Como Rodar Localmente

> ‚ö†Ô∏è Requer ambiente com **PySpark** configurado ou uso do **Databricks Community Edition**.

### 1. Clonar o reposit√≥rio

```bash
git clone https://github.com/seu-usuario/eda-databricks-bronze.git
cd eda-databricks-bronze
